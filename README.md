#Exp1

1.loading nltk.

2.downloading collection book

3.exploring brown,inaugural corpus and webtext.

4.frequency and conditional frequencey distribution.

5.list to string conversion.

#Exp2

1.stemming

2.stemming paragraphs.

3.lemmatizer.

4.chinese segmentation using jieba.

5.text proceesing pipeline.

#homework snowball stemming

#HOMEWORK TOKENIZATION,STEMMING AND TAGGING USING A CORPUS DATA

Language used.
1.English 2.Bengali

#finding frequency and conditional frequency distribution.

#Exp3

1.Lexicons

2.CMU wordlist.

3.Wordnet

4.simple text classifier.

5.vectorizer and cosine similarity.

#Homework parsing grammar

#Exp4

1. Coca Expermient

 
2.
# Gettysburg Address in .txt format

#Remove the stop words.

#Extract and display Bigrams

#From the bigrams,extract collocations.

 #Exp5
 
 1.chunking
 
 #text
 
 #LOR sample 1
 
 2.NER_WEBSCRAPED DATA
 
 #data loading.
 
 #data cleaning.
 
 #tokenization
 
 #Counting labesl and displaying NER'S.
 
 3.chinking
 
 
 #Exp6
 
 1.Mini Project.
 
 #loading langauge.
 
 #tokenization.
 
 #generate similar sentence.
 
 #word_embeddings
 
 #Text completion
 
 #Finding similarity between two sentences
 
 #remove_foreign_languages
 
 #senetence_encoding
 
 #POS tagging.
 
 
 2.Sentiment Analysis Using Logistic Regression.
 
 #Loading the dataset.
 
 #Transforming Doc to Feature Vectors.
 
 #TF and IDF Frequency.
 
 #Tokenizing the document.
 
 #vectorizing the dataset.
 
 #model evaluation
 
 
 
 
 
 
 
 









